{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras and tenosrboard using ngrok.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejanbatanjac/tf/blob/master/Keras_and_tenosrboard_using_ngrok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sCXfQsYeeqhb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# How to use TensorBoard in Colab\n",
        "## Download and unzip ngrok"
      ]
    },
    {
      "metadata": {
        "id": "DZO3EUaPea1E",
        "colab_type": "code",
        "outputId": "32fc60e2-832e-4d4e-eefa-00d6a9325a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-01 07:40:03--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.231.75.48, 52.2.175.150, 52.72.145.109, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.231.75.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14991793 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.30M  13.7MB/s    in 1.0s    \n",
            "\n",
            "2019-05-01 07:40:09 (13.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14991793/14991793]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxlyLTryeAzM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "b0wdo5o8dyzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Fmv_Kj4ewmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run ngrok"
      ]
    },
    {
      "metadata": {
        "id": "SRi8c-KQePas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_8v4ZK5ezdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get URL\n",
        "Run the next cell to start the training before open the url."
      ]
    },
    {
      "metadata": {
        "id": "LYvGuEaMeu-C",
        "colab_type": "code",
        "outputId": "40ee124c-29ca-46b5-c910-4d3585edab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ed76e232.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Aus-alWQe_lD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run a Keras model with TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "4pxUfiLhbS4Y",
        "colab_type": "code",
        "outputId": "20205566-9eae-498e-d2ef-9eeecb18978e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 3\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.2702 - acc: 0.9178 - val_loss: 0.0636 - val_acc: 0.9790\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0910 - acc: 0.9732 - val_loss: 0.0400 - val_acc: 0.9859\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0664 - acc: 0.9801 - val_loss: 0.0373 - val_acc: 0.9866\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0561 - acc: 0.9836 - val_loss: 0.0365 - val_acc: 0.9885\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0325 - val_acc: 0.9901\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0410 - acc: 0.9880 - val_loss: 0.0274 - val_acc: 0.9910\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0384 - acc: 0.9880 - val_loss: 0.0280 - val_acc: 0.9899\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0258 - val_acc: 0.9914\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0313 - acc: 0.9907 - val_loss: 0.0290 - val_acc: 0.9908\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0287 - acc: 0.9911 - val_loss: 0.0265 - val_acc: 0.9912\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0296 - val_acc: 0.9911\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0264 - val_acc: 0.9916\n",
            "Test loss: 0.02636479587158374\n",
            "Test accuracy: 0.9916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vG_TzFoLfXcC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optionally check tensorboard and ngrok PIDs and stop them"
      ]
    },
    {
      "metadata": {
        "id": "3eny77PDeIUL",
        "colab_type": "code",
        "outputId": "2a183fce-bad4-44f2-b426-17da59d70640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root       155  0.3  5.1 39898084 685952 ?     Sl   08:12   0:16 /usr/bin/python2 /usr/local/bin/tensorboard --logdir ./log --host 0.0.0.0 --port 6006\r\n",
            "root       184  107  0.0  33960  5000 pts/0    Ss+  09:37   0:01 /bin/sh -c ps aux | grep tensorboard\r\n",
            "root       186  0.0  0.0  38196  5612 pts/0    S+   09:37   0:00 grep tensorboard\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_VqpJMq5fbF_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "IE1XppLCes0w",
        "colab_type": "code",
        "outputId": "eafd7d35-19ee-4fa0-bfcc-000b0779b7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root       158  0.2  0.1  19512 13724 ?        Sl   08:12   0:11 ./ngrok http 6006\r\n",
            "root       181  108  0.0  33964  4980 pts/0    Ss+  09:37   0:01 /bin/sh -c ps aux | grep ngrok\r\n",
            "root       183  0.0  0.0  38200  5016 pts/0    S+   09:37   0:00 grep ngrok\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0fojLqDgPPk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill 155"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjenJR-nfp4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optionally clear the tensorboard records directory"
      ]
    },
    {
      "metadata": {
        "id": "xALQcQ9mVP-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fBbdhqw-a4X_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}